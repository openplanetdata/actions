name: Download from R2
description: Download files from R2 with optimized bandwidth settings
inputs:
  base_url:
    description: Base URL for HTTP downloads
    required: false
    default: "https://download.openplanetdata.com"
  buffer_size:
    description: Buffer size for I/O operations
    required: false
    default: "2G"
  destination:
    description: Local destination path (default is current directory)
    required: false
    default: "."
  multi_thread_streams:
    description: Number of parallel download streams
    required: false
    default: "768"
  multi_thread_chunk_size:
    description: Chunk size per stream
    required: false
    default: "120M"
  remote_path:
    description: Remote path relative to base URL (e.g., osm/planet/pbf/planet-latest.osm.pbf)
    required: true
  show_progress:
    description: Show download progress
    required: false
    default: "true"
  cache:
    description: Enable caching to skip re-downloading files on the same day
    required: false
    default: "true"
runs:
  using: composite
  steps:
    - name: Install Rclone
      uses: openplanetdata/actions/install-rclone@main
      env:
        RCLONE_CONFIG_DATA: ${{ env.RCLONE_CONFIG_DATA }}

    - name: Download file from R2
      shell: bash
      run: |
        set -euo pipefail

        # Extract filename from remote path
        REMOTE_PATH="${{ inputs.remote_path }}"
        FILENAME=$(basename "$REMOTE_PATH")
        DEST="${{ inputs.destination }}"
        FILE_PATH="$DEST/$FILENAME"
        INFO_FILE="$FILE_PATH.download-info"
        TODAY=$(date -u +%Y%m%d)

        # Check cache if enabled
        SHOULD_DOWNLOAD=true
        if [ "${{ inputs.cache }}" = "true" ]; then
          if [ -f "$FILE_PATH" ] && [ -f "$INFO_FILE" ]; then
            echo "→ Found existing file: $FILENAME"

            # Read cached date from download-info
            CACHED_DATE=$(grep '"date"' "$INFO_FILE" | sed 's/.*"date": "\([^"]*\)".*/\1/' || echo "")

            if [ "$CACHED_DATE" = "$TODAY" ]; then
              echo "✓ Cache valid for today ($TODAY), skipping download"
              SHOULD_DOWNLOAD=false
            else
              echo "→ Cache outdated (cached: $CACHED_DATE, today: $TODAY), removing old files"
              rm -f "$FILE_PATH" "$INFO_FILE"
              echo "✓ Removed outdated file and metadata"
            fi
          else
            echo "→ File or metadata missing, will download"
          fi
        fi

        # Download if needed
        if [ "$SHOULD_DOWNLOAD" = "true" ]; then
          STATS_FLAGS=""
          if [ "${{ inputs.show_progress }}" = "true" ]; then
            STATS_FLAGS="--log-level INFO --stats-log-level INFO --stats=10s --stats-one-line-date"
          fi

          time rclone copy \
            --http-url ${{ inputs.base_url }} :http:${{ inputs.remote_path }} ${{ inputs.destination }} \
            --multi-thread-cutoff 0 \
            --multi-thread-streams ${{ inputs.multi_thread_streams }} \
            --multi-thread-chunk-size ${{ inputs.multi_thread_chunk_size }} \
            --buffer-size ${{ inputs.buffer_size }} \
            --transfers 1 \
            --use-mmap \
            $STATS_FLAGS

          echo "✓ Downloaded: $FILENAME"
        else
          echo "✓ Using cached file: $FILENAME"
        fi

        # Create download metadata file (fields sorted alphabetically)
        CACHED_VALUE=${{ inputs.cache }}
        TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)

        printf '{\n  "cached": %s,\n  "date": "%s",\n  "filename": "%s",\n  "remote_path": "%s",\n  "timestamp": "%s"\n}\n' \
          "$CACHED_VALUE" "$TODAY" "$FILENAME" "$REMOTE_PATH" "$TIMESTAMP" > "$INFO_FILE"

        echo "✓ Created download metadata"
